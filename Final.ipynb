{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49424e2c-b904-479c-b2f3-bdb15b2a4a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8171a873-1acd-4cfb-9b53-3ae78bb7a4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any leading/trailing whitespace from column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c43f552f-3e4f-42b2-8ed3-225aaae17169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created successfully with 2000 students.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import faker\n",
    "\n",
    "# Initialize the Faker library\n",
    "fake = faker.Faker()\n",
    "\n",
    "# Define the number of students\n",
    "num_students = 2000\n",
    "\n",
    "# Define years and departments\n",
    "year_mapping = {\n",
    "    1: (22, '3'),\n",
    "    2: (21, '4'),\n",
    "    3: (23, '2'),\n",
    "    4: (24, '1')\n",
    "}\n",
    "department_codes = {\n",
    "    'Business Systems': '34',\n",
    "    'EEE': '02',\n",
    "    'AIML': '33',\n",
    "    'CSE': '05',\n",
    "    'DS': '32',\n",
    "    'Mech': '07',\n",
    "    'Civil': '01'\n",
    "}\n",
    "data = []\n",
    "for _ in range(num_students):\n",
    "    year, year_str = random.choice(list(year_mapping.values()))\n",
    "    department = random.choice(list(department_codes.keys()))\n",
    "    department_code = department_codes[department]\n",
    "    student_id = f\"{year}091A{department_code}{random.randint(1, 99)}\"\n",
    "    \n",
    "    student_data = {\n",
    "        'ID Number': student_id,\n",
    "        'Student Name': fake.name(),\n",
    "        'Department': department,  # Store the department name\n",
    "        'Year': year_str,\n",
    "        'Percentage': round(random.uniform(0, 100), 2),\n",
    "        'Local Hackathons Participated': random.randint(0, 30),\n",
    "        'Local Hackathons Won': random.randint(0, 10),\n",
    "        'Paper Presentations': random.randint(0, 10),\n",
    "        'National Level Hackathons participated': random.randint(0, 5),\n",
    "        'National Level Hackathons Won': random.randint(0, 5),\n",
    "        'Certifications': random.randint(0, 30),\n",
    "        'R&D Work Rating': random.randint(1, 5),\n",
    "        'Social Interactions': random.randint(0, 10),\n",
    "        'Paper Publications': random.randint(0, 30),\n",
    "    }\n",
    "    \n",
    "    data.append(student_data)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('students.csv', index=False)\n",
    "\n",
    "print(\"Dataset created successfully with 2000 students.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f7196399-6fd9-4d26-85c3-b84afb0a0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e9195820-5650-45e4-9904-69abc77ed667",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('students.csv')\n",
    "df.isnull().sum()\n",
    "df.columns = df.columns.str.strip()\n",
    "columns_to_normalize = [\n",
    "    'Percentage',\n",
    "    'Local Hackathons Participated',\n",
    "    'Local Hackathons Won',\n",
    "    'Paper Presentations',\n",
    "    'National Level Hackathons participated',\n",
    "    'National Level Hackathons Won',\n",
    "    'Certifications',\n",
    "    'R&D Work Rating',\n",
    "    'Social Interactions',\n",
    "    'Paper Publications'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5293e5bc-c98c-466b-9977-6d18afb6d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_to_normalize:\n",
    "    if column in df.columns:\n",
    "        max_value = df[column].max()\n",
    "        if max_value > 0:  # Prevent division by zero\n",
    "            df[column] = df[column] / max_value\n",
    "        else:\n",
    "            print(f\"Max value for '{column}' is zero, skipping normalization.\")\n",
    "    else:\n",
    "        print(f\"Column '{column}' not found in the DataFrame.\")\n",
    "label_encoder = LabelEncoder()\n",
    "if 'Student Name' in df.columns:\n",
    "    df['Student Name'] = label_encoder.fit_transform(df['Student Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "31bb9d58-44ea-40d8-ad76-b2b5e15936d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'Percentage': 0.25,  # 25% weight  # 8% weight\n",
    "    'Local Hackathons Participated': 0.07,\n",
    "    'Local Hackathons Won': 0.08,# 7% weight\n",
    "    'Paper Presentations': 0.08,  # 8% weight\n",
    "    'Paper Presentations': 0.07,  # 7% weight\n",
    "    'National Level Hackathons Won': 0.12,  # 12% weight\n",
    "    'Certifications': 0.1,  # 10% weight\n",
    "    'R&D Work Rating': 0.08,  # 8% weight\n",
    "    'Social Interactions': 0.05,  # 5% weight\n",
    "    'Paper Publications': 0.1   # 10% weight\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "00606767-ad09-4dab-a3c3-928ee661afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Initial Performance Score'] = sum(df[column] * weight for column, weight in weights.items())\n",
    "df['Rank'] = df['Initial Performance Score'].rank(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1c638486-9fc8-41dc-81d6-6569fb228e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_students_initial = df.nlargest(3, 'Initial Performance Score')\n",
    "features = df.drop(columns=['ID Number', 'Year', 'Initial Performance Score', 'Rank','Department'])\n",
    "target = df['Initial Performance Score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "206e9d01-76ac-4ff1-8bcf-36b2f7260b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as model.pkl\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "model_path = r'C:\\Users\\kalpa\\Desktop\\Hackathon\\model.pkl'\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(\"Model saved as model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6876ff14-b4a1-4d23-9720-d408c6822f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation:\n",
      "Mean Squared Error: 0.0014\n",
      "R² Score: 0.8820\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"\\nModel Evaluation:\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7af8731c-4efc-4546-8cd2-dd7eec95bc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the year to get the top 3 students using ML predictions:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 Students for the year 1 using ML predictions:\n",
      "       ID Number  Student Name  Predicted Performance Score Department\n",
      "1037  24091A3363          1859                     0.695229       AIML\n",
      "392   24091A3278           384                     0.691967         DS\n",
      "1318  24091A0555           905                     0.682670        CSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalpa\\AppData\\Local\\Temp\\ipykernel_54700\\853799521.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  year_data['Predicted Performance Score'] = model.predict(year_data.drop(columns=['ID Number', 'Year', 'Initial Performance Score', 'Rank','Department']))\n"
     ]
    }
   ],
   "source": [
    "year_input = int(input(\"Enter the year to get the top 3 students using ML predictions: \"))\n",
    "\n",
    "# Filter the data for the specified year\n",
    "year_data = df[df['Year'] == year_input]\n",
    "if year_data.empty:\n",
    "    print(f\"No data found for the year {year_input}.\")\n",
    "else:\n",
    "    # Make predictions on the filtered year data\n",
    "    year_data['Predicted Performance Score'] = model.predict(year_data.drop(columns=['ID Number', 'Year', 'Initial Performance Score', 'Rank','Department']))\n",
    "\n",
    "    # Getting top 3 students based on predicted performance score\n",
    "    top_students_ml = year_data[['ID Number', 'Student Name', 'Predicted Performance Score','Department']].nlargest(3, 'Predicted Performance Score')\n",
    "    \n",
    "    # Display the top 3 students\n",
    "    print(f\"\\nTop 3 Students for the year {year_input} using ML predictions:\")\n",
    "    print(top_students_ml)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2719b6ea-0bf4-45eb-99e8-15d66ccbf593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final code\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Load the dataset\n",
    "df = pd.read_csv('students.csv')\n",
    "df.isnull().sum()\n",
    "df.columns = df.columns.str.strip()\n",
    "columns_to_normalize = [\n",
    "    'Percentage',\n",
    "    'Local Hackathons Participated',\n",
    "    'Local Hackathons Won',\n",
    "    'Paper Presentations',\n",
    "    'National Level Hackathons participated',\n",
    "    'National Level Hackathons Won',\n",
    "    'Certifications',\n",
    "    'R&D Work Rating',\n",
    "    'Social Interactions',\n",
    "    'Paper Publications'\n",
    "]\n",
    "for column in columns_to_normalize:\n",
    "    if column in df.columns:\n",
    "        max_value = df[column].max()\n",
    "        if max_value > 0:  # Prevent division by zero\n",
    "            df[column] = df[column] / max_value\n",
    "        else:\n",
    "            print(f\"Max value for '{column}' is zero, skipping normalization.\")\n",
    "    else:\n",
    "        print(f\"Column '{column}' not found in the DataFrame.\")\n",
    "label_encoder = LabelEncoder()\n",
    "if 'Student Name' in df.columns:\n",
    "    df['Student Name'] = label_encoder.fit_transform(df['Student Name'])\n",
    "weights = {\n",
    "    'Percentage': 0.25,  # 25% weight  # 8% weight\n",
    "    'Local Hackathons Participated': 0.07,\n",
    "    'Local Hackathons Won': 0.08,# 7% weight\n",
    "    'Paper Presentations': 0.08,  # 8% weight\n",
    "    'Paper Presentations': 0.07,  # 7% weight\n",
    "    'National Level Hackathons Won': 0.12,  # 12% weight\n",
    "    'Certifications': 0.1,  # 10% weight\n",
    "    'R&D Work Rating': 0.08,  # 8% weight\n",
    "    'Social Interactions': 0.05,  # 5% weight\n",
    "    'Paper Publications': 0.1   # 10% weight\n",
    "}\n",
    "df['Initial Performance Score'] = sum(df[column] * weight for column, weight in weights.items())\n",
    "df['Rank'] = df['Initial Performance Score'].rank(ascending=False)\n",
    "\n",
    "# Display the top 3 students based on the initial score\n",
    "top_students_initial = df.nlargest(3, 'Initial Performance Score')\n",
    "features = df.drop(columns=['ID Number', 'Year', 'Initial Performance Score', 'Rank','Department'])\n",
    "target = df['Initial Performance Score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Regressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "model_path = r'C:\\Users\\kalpa\\Desktop\\Hackathon\\model.pkl'\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "print(\"Model saved as model.pkl\")\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"\\nModel Evaluation:\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "year_input = int(input(\"Enter the year to get the top 3 students using ML predictions: \"))\n",
    "\n",
    "# Filter the data for the specified year\n",
    "year_data = df[df['Year'] == year_input]\n",
    "if year_data.empty:\n",
    "    print(f\"No data found for the year {year_input}.\")\n",
    "else:\n",
    "    # Make predictions on the filtered year data\n",
    "    year_data['Predicted Performance Score'] = model.predict(year_data.drop(columns=['ID Number', 'Year', 'Initial Performance Score', 'Rank','Department']))\n",
    "\n",
    "    # Getting top 3 students based on predicted performance score\n",
    "    top_students_ml = year_data[['ID Number', 'Student Name', 'Predicted Performance Score','Department']].nlargest(3, 'Predicted Performance Score')\n",
    "    \n",
    "    # Display the top 3 students\n",
    "    print(f\"\\nTop 3 Students for the year {year_input} using ML predictions:\")\n",
    "    print(top_students_ml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
